# Probability Distributions {#dist}

이 단원에서는 실제로 많이 쓰이는 확률 분포 몇 개와 그 성질들을 간략히 요약하고자 합니다.
결과는 모두 [@bishop_2006]의 Appendix B에 있으니 참고하시길 바랍니다.
과정은 대개 다음과 같이 이루어질 것입니다.

* 확률 분포 정의
* 대푯값(Representative value) 계산
* 최대가능도추정(Maximally Likelihood Estimation)
* Bayesian Update
* Random number generator (Programming)

편의상 증명은 대부분 영어로 진행하겠습니다.

## Binary Variables

### Bernoulli Distribution

------------------------------------------------------------------------
**Definition 5.1.1 - Bernoulli distribution**

Let consider a single binary random variable $x\in\{0,1\}$.
Suppose the probability of $x=1$ is given as $p(x=1|\mu) = \mu$ where
$0\leq \mu \leq 1$ then
$$\text{Bern}(x|\mu) = \mu^x(1 - \mu)^{1-x}$$
is called **Bernoulli distribution**.
------------------------------------------------------------------------

------------------------------------------------------------------------
**Property 5.1.2 - Representative values of Bernouli distribution **

Let $\text{Bern}(x|\mu)$ be given Bernoulli distribution. Then
$$\begin{align}
    \mathbb{E}[x] &= \mu \\
    \text{var}[x] &= \mu(1-\mu)
\end{align}$$
------------------------------------------------------------------------

------------------------------------------------------------------------
**Theorem 5.1.3 - MLE for Bernoulli distribution **

Let $\mathcal{D} = \{x_1, \cdots, x_N\}$ be *i.i.d* data belong to
$\text{Bern}(x|\mu)$. Applying maximally likelihood estimation, then
$$\mu_{ML} = \frac{1}{N}\sum_{i=1}^N x_n $$
------------------------------------------------------------------------

**Proof for Thm 5.1.3**

Since there is *i.i.d* assumption, the likelihood given as
$$p(\mathcal{D}|\mu) = \prod_{n=1}^N p(x_n | \mu) = \prod_{n=1}^N \mu^{x_n} (1 - \mu)^{1-x_n}$$
For convenience, let's obtain log likelihood.
$$\begin{align}
    \ln p(\mathcal{D}| \mu) = \sum_{n=1}^N \ln p(x_n | \mu) &= \sum_{n=1}^N \left\{x_n \ln \mu + (1-x_n)\ln(1-\mu) \right\}\\
    &= \ln \mu \sum_{n=1}^N x_n + \ln(1-\mu) \sum_{n=1}^N (1-x_n) \\
    &= (\ln\mu - \ln(1-\mu))\sum_{n=1}^N x_n + N \ln(1-\mu)
\end{align}$$
Then for MLE, let's differentiate log likelihood with $\mu$.
$$\frac{\partial}{\partial \mu}\ln p(\mathcal{D}|\mu) = \frac{1}{\mu}\sum_{n=1}^N x_n - \frac{1}{1-\mu}\sum_{n=1}^N (1 - x_n) = 0$$
Therefore we can find $\mu_{ML}$.
$$\therefore\,\mu_{ML} = \frac{1}{N}\sum_{n=1}^N x_n$$

이번에는 균등 분포(Uniform distribution)로 부터 베르누이 분포를 구현해보도록 하겠습니다.

------------------------------------------------------------------------
**Algorithm 5.1.4 - Uniform to Bernoulli **

We want to generate $X \sim \text{Bern}(x | \mu)$. <br/>
1. Generate $U \sim \text{Unif}(0,1)$ <br/>
2. If $U \leq \mu$ where $\mu \in [0, 1]$ then $X = 1$ else $X = 0$.
------------------------------------------------------------------------

이 간단한 알고리즘을 Rust를 이용해서 나타내면 다음과 같습니다.

```rust
// Generate 100 samples of Bern(x|0.1)
extern crate rand;
use rand::prelude::*;

fn main() {
    let sample_size = 100;
    let mut rng = thread_rng();
    let mut v = vec![0usize; 100];
    let mu: f64 = 0.1;

    for i in 0 .. sample_size {
        let u = rng.gen_range(0f64, 1f64);
        if u <= mu {
            v[i] = 1;
        } else {
            v[i] = 0;
        }
    }

    println!("Samples:\n{:?}", v);
}
```

이미 구현되어 있는 라이브러리인 [Peroxide](https://crates.io/crates/peroxide)을 사용한 결과는 다음과 같습니다.

```rust
extern crate peroxide;
use peroxide::*;

fn main() {
    let b = Bernoulli(0.1);
    let b_samples = b.sample(100);
    b.print();
}
```

### Beta Distribution

------------------------------------------------------------------------
**Definition 5.1.5 - Beta Distribution **

**The Beta distribution** is a family of continuous probability distributions
defined on the interval $[0, 1]$ parametrized by two positive shape parameters,
denoted by $\alpha$ and $\beta$ :
$$\text{Beta}(\mu | \alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \mu^{\alpha-1}(1-\mu)^{\beta - 1}$$
------------------------------------------------------------------------

------------------------------------------------------------------------
**Property 5.1.6 - Normalization of Beta distribution **

$$\int_0^1 \text{Beta}(\mu | \alpha, \beta) d\mu = 1$$
------------------------------------------------------------------------

**Proof for Prop 5.1.6**

To prove this, we should show next relation.
$$\int_0^1 \mu^{\alpha - 1}(1 - \mu)^{\beta - 1}d\mu = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}$$
Then let's start proof.
\begin{align}
    \Gamma(\alpha)\Gamma(\beta) &= \int_0^\infty \mu^{\alpha - 1}e^{-\mu}d\mu \int_0^\infty \nu^{\beta - 1}e^{-\nu}d\nu \\
    &= \int_0^\infty \int_0^\infty \mu^{\alpha - 1}\nu^{\beta-1}e^{-(\mu + \nu)} d\mu d\nu \\
    &= \int_0^\infty \left(\int_\mu^\infty \mu^{\alpha-1}(t-\mu)^{\beta - 1} e^{-t} dt\right)d\mu \\
\end{align}

For last line of above equations, I used the substitution $t = \mu + \nu,~ dt = d\nu$.
Next, let change order of integration.
\begin{align}
    \Gamma(\alpha)\Gamma(\beta) &= \int_0^\infty \left(\int_0^t \mu^{\alpha-1}(t-\mu)^{\beta-1}d\mu\right)e^{-t}dt \\
    &= \int_0^\infty \left(\int_0^1 (t\mu')^{\alpha-1}t^{\beta-1}(1-\mu')^{\beta-1}t d\mu'\right)e^{-t}dt \\
    &= \int_0^\infty \left(\int_0^1 t^{\alpha + \beta - 1} \mu'^{\alpha-1} (1- \mu')^{\beta-1} d\mu'\right)e^{-t}dt \\
    &= \int_0^\infty t^{\alpha + \beta - 1} e^{-t}dt \cdot \int_0^1 \mu'^{\alpha-1}(1-\mu')^{\beta-1}d\mu'
\end{align}

$$\therefore \int_0^1 \mu^{\alpha - 1}(1-\mu)^{\beta-1}d\mu = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}$$

Then proof is finish.

------------------------------------------------------------------------
**Property 5.1.7 - Representative values of Beta distribution **

Let $\text{Beta}(\mu | \alpha, \beta)$ be a given Beta distribution, then
$$\begin{aligned}
\mathbb{E}[\mu] &= \frac{\alpha}{\alpha + \beta} \\
\text{var}[\mu] &= \frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)} \\
\text{mode}[\mu] &= \frac{\alpha - 1}{\alpha + \beta - 2}
\end{aligned}$$
------------------------------------------------------------------------

**Proof for prop 5.1.7**

First, let's see expectation value.
\begin{align}
    \mathbb{E}[\mu] &= \int_0^1 \mu \cdot \text{Beta}(\mu|\alpha, \beta)d\mu \\
    &= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \int_0^1 \mu \cdot \mu^{\alpha - 1}(1 - \mu)^{\beta - 1} d\mu \\
    &= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \int_0^1 \mu^{\alpha}(1-\mu)^{\beta-1}d\mu \\
    &= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \cdot \frac{\Gamma(\alpha + 1)\Gamma(\beta)}{\Gamma(\alpha + \beta + 1)} \\
    &= \frac{\alpha}{\alpha + \beta}
\end{align}

Next, see variation.
\begin{align}
    \text{var}[\mu] &= \int_0^1 \mu^2 \cdot \text{Beta}(\mu | \alpha, \beta)d\mu - \left(\frac{\alpha}{\alpha + \beta}\right)^2 \\
    &= \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \cdot \frac{\Gamma(\alpha + 2)\Gamma(\beta)}{\Gamma(\alpha + \beta + 2)} - \left(\frac{\alpha}{\alpha + \beta}\right)^2 \\
    &= \frac{\alpha(\alpha + 1)}{(\alpha + \beta)(\alpha + \beta + 1)} - \left(\frac{\alpha}{\alpha + \beta}\right)^2 \\
    &= \frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}
\end{align}

Before viewing mode, we should differentiate Beta distribution under specific condition. $(\alpha, \beta > 1)$.
$$\frac{\partial}{\partial \mu}\text{Beta}(\mu | \alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \left((\alpha- 1) \mu^{\alpha - 2}(1 - \mu)^{\beta - 1} - (\beta - 1)\mu^{\alpha - 1}(1 - \mu)^{\beta - 2} \right)$$

Thus, we can find value of $\mu$ directly.
\begin{align}
    &(\alpha - 1)(1 - \mu) - (\beta - 1)\mu = 0 \\
    \Rightarrow ~ &\mu = \frac{\alpha - 1}{\alpha + \beta - 2}
\end{align}