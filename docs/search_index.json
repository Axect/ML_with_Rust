[
["index.html", "Machine Learning with Rust Chapter 1 Preface", " Machine Learning with Rust Tae Geun Kim 2019-01-28 Chapter 1 Preface 최근들어 기계학습(Machine Learning)은 점차 중요해지고 있습니다. 학습된 기계들은 바둑이나 게임에서부터 프로들을 가뿐히 눌렀고, 연구나 업무를 훨씬 효율적으로 해결합니다. 그러나 단순히 모두가 한다고 해서 섣부르게 시작하다가는 결과가 나와도 해석하지 못하거나 혹은 애초에 잘못된 결과가 나올 수도 있습니다. 따라서 이 책에서는 단순히 Machine Learning Framework를 사용하는 것이 아닌, 밑바닥부터 차근차근 이론을 적용하여 Machine Learning을 학습하고자 합니다. 그러기 위해서 우리는 Rust라는 프로그래밍 언어와 매우 유명한 Bishop의 교재(Bishop 2006)를 사용할 것입니다. 그럼 이제 바로 시작해봅시다. References "],
["intro.html", "Chapter 2 Introduction", " Chapter 2 Introduction 과학이란, 굉장히 포괄적인 행위라 한 마디로 정의하는 것이 어렵지만, 공통적인 특징으로는 자연을 관측한 결과를 분석하여 정해진 모델로 분류한다는 것이 있습니다. 이를 수학에서의 표현방식을 빌려와서 나타내면 다음과 같습니다. Observation: \\(x\\in \\mathbb{R}^d\\) Class(or Category): \\(y \\in \\left\\{ 1,2,\\cdots,M\\right\\}\\) Classifier: \\(g: \\mathbb{R}^d \\rightarrow \\{ 1, 2, \\cdots, M\\}\\) Error: Quantity to measure difference between \\(g(x), ~y\\) 우리의 궁극적인 목적은 관측값을 적절한 모델로 분류하는 분류기인 \\(g\\)를 찾는 것입니다. 모든 상황에 통용되는 \\(g\\)를 찾을 수 있다면 좋겠지만 안타깝게도 그런 \\(g\\)는 존재하지 않습니다. 하나의 관측 값이 항상 하나의 모델에만 대응되는 것도 아닐뿐더러, 관측 상황조차 같지 않기 때문이죠. 따라서 분류기에는 항상 error가 존재합니다. 즉, 우리의 관측은 비결정론적(Undeterministic)이고, 이를 표현하기 위해서는 기존의 데카르트 방식인 결정론적 수학을 넘어서야 합니다. 우리는 이러한 이론을 확률론(Probabilistic Theory)이라 부릅니다. 확률론을 적용하기 위하여 변수를 단순히 일차원적으로 보는 것이 아니라 변수와 모델을 엮은 하나의 Pair를 메인 변수로 볼 것입니다. 이렇게 하면 보다 쉽게 Error의 정도를 명시할 수 있습니다. Random pair: \\((X, Y) \\in \\mathbb{R}^d \\times \\{1,2,\\cdots,M\\}\\) Probability of Error: \\(L(g) = \\mathbf{P}\\{g(X) \\neq Y\\}\\) 그리고 이를 활용해 가장 이상적인 분류기를 정의내릴 수 있습니다. \\[g^* = \\underset{g:\\mathbb{R}^d \\rightarrow \\{1,2,\\cdots,M\\}}{\\text{argmin}}L(g)\\] 위 수식은 데이터를 모델로 분류하는 분류기들 중에 Error 확률을 가장 최소로 만드는 분류기를 택한다는 것으로 해석할 수 있습니다. 그러나 안타깝게도 우리는 전체 분류기 집단을 알지도 못할 뿐더러 \\((X,Y)\\)에 대한 확률분포조차 주어져있지 않습니다. 하지만 다행히 수 많은 연구자들이 많은 데이터를 손수 분류해놓았고 우리는 지금까지 누적된 이러한 데이터들로 분류기를 만들 수 있습니다. 물론, 데이터들의 원래 분포도 알 수 없거나 알기 힘들어서 사용하는데에 지장이 많지만 아주 강력하지만 효율적인 조건을 사용하면 이를 쉽게 해결할 수 있다는 것이 입증되어 있습니다. 바로 Independent Identically Distributed (i.i.d) 가정입니다. 이제 이를 좀 더 수학적으로 모델링하겠습니다. Pre-classified data: \\(\\{(X_i, Y_i)\\}^n_{i=1}\\) Classifier (Trained): \\(g_n: \\mathbb{R}^d \\times (\\mathbb{R}^d \\times \\{1,\\cdots, M\\})^n \\rightarrow \\{1,\\cdots,M\\}\\) Conditional probability of error: \\(L_n = L(g_n) = \\mathbf{P}\\left\\{g_n\\left(X;\\left\\{(X_i, Y_i)\\right\\}_{i=1}^n\\right) \\neq Y \\, |\\, \\left\\{(X_i, Y_i) \\right\\}_{i=1}^n\\right\\}\\) Average of \\(L_n\\): \\(\\mathbf{E}L_n\\) 위에서 마지막에 소개한 \\(L_n\\)의 평균값은 앞으로 우리가 주로 다룰 중요한 변수입니다. 앞으로 우리가 데이터를 다룰 방법은 통계적 방법인데, 이 방법 하에서는 개개인의 에러는 중요하지 않고 전체적인 에러의 평균만이 중요합니다. 따라서 \\(L_n\\)의 평균값을 이용하여 각 분류기의 성능을 평가할 것입니다. 이제 기계학습의 기초에 대한 수학적 서술은 대강 끝났습니다. 앞으로의 목표는 \\(\\mathbf{E}L_n\\)을 최소화 시키는 것이고 이를 위해 확률론을 사용할 것입니다. 다만, 확률론을 공부하기 위해서는 필수로 공부해야 하는 학문이 있는데, 바로 측도론(Measure Theory)입니다. "],
["measure.html", "Chapter 3 Measure Theory 3.1 \\(\\sigma\\)-algebra", " Chapter 3 Measure Theory 측도론이란, 간단히 말하면 집합의 크기를 측정하기 위한 학문입니다. 특히, 함수공간과 확률공간 같이 추상적인 공간을 다룰 때에 중요한 학문이죠. 우리는 흔히 고등학교 과정에서 확률과 통계를 접하고는 확률을 다룰 수 있다라고 착각합니다. 예를 들어, 확률이란 무엇인가? 라는 질문에 대해서 보통 다음과 같은 정의를 인용할 것입니다. Example 1 - High School Probability Probability of occurrence of events \\(A\\) in sample space \\(\\Omega\\) is \\[ \\mathbf{P}(A) = \\frac{n(A)}{n(\\Omega)}\\] 위의 정의를 이용하면 아주 간단명료하게 수학적 확률을 계산할 수 있습니다. 예를 들어, 주사위를 던졌을 때, 1이 나올 확률은 \\(\\left\\{1,2,3,4,5,6 \\right\\}\\)을 전체집합으로 설정하면 전체 6개 중에 1이 발생할 사건은 1개이기에 확률은 \\(\\frac{1}{6}\\)이 됩니다. 하지만, 다음의 경우에는 난처해집니다. Example 2 - Common High School Problem 정사각형 과녁 안에 원 모양 과녁이 네 변에 모두 내접하여 있을 때, 화살이 원 안에 명중할 확률을 구하여라. 간단한 확률 지식이 있는 사람이라면 이 문제를 \\(\\frac{\\text{원의 넓이}}{\\text{전체 정사각형의 넓이}}\\)로 접근하여 \\(\\frac{\\pi}{4}\\)임을 알아낼 수 있을 것입니다. 그런데 이는 앞에서의 정의와 대치됩니다. 분명 우리가 배운 정의에 의하면 사건이 발생할 경우의 수를 전체 경우의 수로 나누어 구해야 하는데, 전체 경우의 수는 얼마일까요? 하다 못해 원의 경우의 수는 어떻게 접근해야 할까요? 우리는 지금까지 아무런 의심 없이 구해왔습니다만, 이제부터 의심을 가질 필요가 있습니다. 확률은 특정 경우에서는 경우의 수 문제로 치환될 수 있지만, 집합이 무한해지는 순간 우리가 정의한 확률에 부합하지 않게 됩니다. 따라서 우리는 확률을 보다 엄밀하게 정의해야할 필요가 있습니다. 그리고 그것을 위해서는 먼저 집합의 크기를 정의해야 합니다. 바로 이를 위해서 측도론이 필요한 것입니다. 이제 측도론의 필요성은 잘 알았지만, 측도론은 상당히 추상적인 학문이라 곧바로 집합의 크기를 정의내릴 수는 없습니다. 집합의 크기가 무엇이다 말하기 전에 측정 가능한 집합에 대해서 먼저 논의해봅시다. 일단, 측정도 모르고 측정 가능성도 모르겠지만 일단 어떤 집합 \\(U, V\\)가 크기를 잴 수 있는 집합(가측집합; Measurable Set)이라 전제해봅시다. 그렇다면 직관적으로 다음의 사실들을 받아 들일 수 있습니다. \\(U\\cup V\\) is measurable \\(U \\cap V\\) is measurable \\(U^c,~ V^c\\) is measurable 하지만 수학자들은 이런 모호한 직관으로서의 정의를 좋아하지 않습니다. 이런 규칙들을 모아 좀 더 엄밀한 표현으로 바꾸어 하나의 우아한 규칙으로 정의내리고 받아들입니다. 수학에서 이러한 규칙을 대수(Algebra)라고 부릅니다. 3.1 \\(\\sigma\\)-algebra Definition 1 - \\(\\sigma\\)-algebra Let \\(S\\) be a set, and let \\(\\mathcal{F}\\) be a family of subsets of \\(S\\). \\(\\mathcal{F}\\) is called a \\(\\sigma\\)-algebra if 1. \\(\\emptyset \\in \\mathcal{F}\\) 2. \\(A \\in \\mathcal{F}\\) implies \\(A^c \\in \\mathcal{F}\\) 3. \\(A_1, A_2,\\cdots \\in \\mathcal{F}\\) implies \\(\\bigcup_{i=1}^\\infty A_i \\in \\mathcal{F}\\) 정의는 무척 복잡해보이지만, 사실 의미 자체는 간단합니다. 대수는 일종의 규칙을 담아 놓은 집합입니다. 예를 들어, 위상수학에서의 Topology는 모든 열린 집합들의 집합이고, 여기서 말하는 \\(\\sigma\\)-algebra(시그마대수)는 모든 가측집합들의 집합입니다. 정의자체도 하나씩 살펴보면 충분히 납득이 가능합니다. 공집합은 당연하게도 크기가 0일 것이므로 측정가능한 집합이며, 어떤 집합 \\(A\\)가 측정가능하다면 (이를 수학에서는 \\(A\\in\\mathcal{F}\\)라 표현합니다.) 그의 여집합 또한 측정할 수 있을 것입니다. 마지막으로 측정 가능한 집합들의 합집합 또한 측정 가능할 것입니다. 이 외에도 전체집합이 측정가능하다는 사실을 1번과 2번 정의로부터 이끌어낼 수 있고, 2번과 3번 정의를 이용하면 합집합 뿐만 아니라 교집합 또한 측정 가능하다는 사실을 유추해낼 수 있습니다. 이제 대수를 정의하였으니 우리가 다룰 공간을 명시해봅시다. Definition 2 - Measurable Space Let \\(S\\) be a set, and let \\(\\mathcal{F}\\) be a \\(\\sigma\\)-algebra of subsets of \\(S\\). Then \\((S, \\mathcal{F})\\) is called a measurable space. The elements of \\(\\mathcal{F}\\) are called measurable sets. 이제 기본 틀은 정리했으니 적응하기 위하여 조금 더 생각을 해봅시다. 어떤 집합 \\(S\\)에 대하여 가장 작은 \\(\\sigma\\)-algebra와 가장 큰 \\(\\sigma\\)-algebra는 뭘까요? 일단, 정의에 의해 공집합은 무조건 측정가능하고 두 번째 정의에 의해 전체집합도 측정가능하므로 가장 작은 시그마대수는 \\(\\mathcal{F} = \\left\\{\\emptyset, S \\right\\}\\)가 됩니다. 또한 시그마 대수는 어떤 집합의 부분집합의 모임이기 때문에 모든 부분집합의 집합(멱집합; Power set)이 가장 큰 시그마 대수가 될 것입니다. 이는 \\(\\mathcal{F} = \\mathcal{P}(S)\\)로 표기합니다. 고등학교 시절에 부분집합을 배울 때, 어떤 집합을 포함하는 부분집합의 개수는? 이라는 문제를 본 적이 있을 겁니다. 되게 의미 없는 일 같지만 수학에서는 어떤 집합을 포함하고 있는 지의 여부가 상당히 중요합니다. 시그마 대수에서도 마찬가지인데 어떤 집합을 반드시 포함하고 있는 시그마 대수를 “그 집합에 의하여 발생한 시그마 대수이다” 라고 정의할 것입니다. 수학적 정의는 다음과 같습니다. Definition 3 - Generated \\(\\sigma\\)-algebra Let \\(S\\) be a set and \\(G\\) be a family of subsets of \\(S\\). The smallest \\(\\sigma\\)-algbera which contains \\(G\\) is called generated \\(\\sigma\\)-algebra with respect to \\(G\\) denoted by \\(\\sigma(G)\\). 이제 이 정의를 아주 유명한 규칙 공간에 적용해보겠습니다. 바로 위상공간(Topological Space)에 말이죠. "],
["methods.html", "Chapter 4 Methods", " Chapter 4 Methods We describe our methods in this chapter. "],
["applications.html", "Chapter 5 Applications 5.1 Example one 5.2 Example two", " Chapter 5 Applications Some significant applications are demonstrated in this chapter. 5.1 Example one 5.2 Example two "],
["final-words.html", "Chapter 6 Final Words", " Chapter 6 Final Words We have finished a nice book. "],
["references.html", "References", " References "]
]
