[
["index.html", "Machine Learning with Rust Chapter 1 Preface", " Machine Learning with Rust Tae Geun Kim 2019-01-29 Chapter 1 Preface 최근들어 기계학습(Machine Learning)은 점차 중요해지고 있습니다. 학습된 기계들은 바둑이나 게임에서부터 프로들을 가뿐히 눌렀고, 연구나 업무를 훨씬 효율적으로 해결합니다. 그러나 단순히 모두가 한다고 해서 섣부르게 시작하다가는 결과가 나와도 해석하지 못하거나 혹은 애초에 잘못된 결과가 나올 수도 있습니다. 따라서 이 책에서는 단순히 Machine Learning Framework를 사용하는 것이 아닌, 밑바닥부터 차근차근 이론을 적용하여 Machine Learning을 학습하고자 합니다. 그러기 위해서 우리는 Rust라는 프로그래밍 언어와 매우 유명한 Bishop의 교재(Bishop 2006), 그리고 좀 더 엄밀한 이론을 위하여 뤽 데브로이의 책(Devroye 1996) 역시 사용할 것입니다. 그럼 이제 바로 시작해봅시다. References "],
["intro.html", "Chapter 2 Introduction", " Chapter 2 Introduction 과학이란, 굉장히 포괄적인 행위라 한 마디로 정의하는 것이 어렵지만, 공통적인 특징으로는 자연을 관측한 결과를 분석하여 정해진 모델로 분류한다는 것이 있습니다. 이를 수학에서의 표현방식을 빌려와서 나타내면 다음과 같습니다. Observation: \\(x\\in \\mathbb{R}^d\\) Class(or Category): \\(y \\in \\left\\{ 1,2,\\cdots,M\\right\\}\\) Classifier: \\(g: \\mathbb{R}^d \\rightarrow \\{ 1, 2, \\cdots, M\\}\\) Error: Quantity to measure difference between \\(g(x), ~y\\) 우리의 궁극적인 목적은 관측값을 적절한 모델로 분류하는 분류기인 \\(g\\)를 찾는 것입니다. 모든 상황에 통용되는 \\(g\\)를 찾을 수 있다면 좋겠지만 안타깝게도 그런 \\(g\\)는 존재하지 않습니다. 하나의 관측 값이 항상 하나의 모델에만 대응되는 것도 아닐뿐더러, 관측 상황조차 같지 않기 때문이죠. 따라서 분류기에는 항상 error가 존재합니다. 즉, 우리의 관측은 비결정론적(Undeterministic)이고, 이를 표현하기 위해서는 기존의 데카르트 방식인 결정론적 수학을 넘어서야 합니다. 우리는 이러한 이론을 확률론(Probabilistic Theory)이라 부릅니다. 확률론을 적용하기 위하여 변수를 단순히 일차원적으로 보는 것이 아니라 변수와 모델을 엮은 하나의 Pair를 메인 변수로 볼 것입니다. 이렇게 하면 보다 쉽게 Error의 정도를 명시할 수 있습니다. Random pair: \\((X, Y) \\in \\mathbb{R}^d \\times \\{1,2,\\cdots,M\\}\\) Probability of Error: \\(L(g) = \\mathbf{P}\\{g(X) \\neq Y\\}\\) 그리고 이를 활용해 가장 이상적인 분류기를 정의내릴 수 있습니다. \\[g^* = \\underset{g:\\mathbb{R}^d \\rightarrow \\{1,2,\\cdots,M\\}}{\\text{argmin}}L(g)\\] 위 수식은 데이터를 모델로 분류하는 분류기들 중에 Error 확률을 가장 최소로 만드는 분류기를 택한다는 것으로 해석할 수 있습니다. 그러나 안타깝게도 우리는 전체 분류기 집단을 알지도 못할 뿐더러 \\((X,Y)\\)에 대한 확률분포조차 주어져있지 않습니다. 하지만 다행히 수 많은 연구자들이 많은 데이터를 손수 분류해놓았고 우리는 지금까지 누적된 이러한 데이터들로 분류기를 만들 수 있습니다. 물론, 데이터들의 원래 분포도 알 수 없거나 알기 힘들어서 사용하는데에 지장이 많지만 아주 강력하지만 효율적인 조건을 사용하면 이를 쉽게 해결할 수 있다는 것이 입증되어 있습니다. 바로 Independent Identically Distributed (i.i.d) 가정입니다. 이제 이를 좀 더 수학적으로 모델링하겠습니다. Pre-classified data: \\(\\{(X_i, Y_i)\\}^n_{i=1}\\) Classifier (Trained): \\(g_n: \\mathbb{R}^d \\times (\\mathbb{R}^d \\times \\{1,\\cdots, M\\})^n \\rightarrow \\{1,\\cdots,M\\}\\) Conditional probability of error: \\(L_n = L(g_n) = \\mathbf{P}\\left\\{g_n\\left(X;\\left\\{(X_i, Y_i)\\right\\}_{i=1}^n\\right) \\neq Y \\, |\\, \\left\\{(X_i, Y_i) \\right\\}_{i=1}^n\\right\\}\\) Average of \\(L_n\\): \\(\\mathbf{E}L_n\\) 위에서 마지막에 소개한 \\(L_n\\)의 평균값은 앞으로 우리가 주로 다룰 중요한 변수입니다. 앞으로 우리가 데이터를 다룰 방법은 통계적 방법인데, 이 방법 하에서는 개개인의 에러는 중요하지 않고 전체적인 에러의 평균만이 중요합니다. 따라서 \\(L_n\\)의 평균값을 이용하여 각 분류기의 성능을 평가할 것입니다. 이제 기계학습의 기초에 대한 수학적 서술은 대강 끝났습니다. 앞으로의 목표는 \\(\\mathbf{E}L_n\\)을 최소화 시키는 것이고 이를 위해 확률론을 사용할 것입니다. 다만, 확률론을 공부하기 위해서는 필수로 공부해야 하는 학문이 있는데, 바로 측도론(Measure Theory)입니다. "],
["measuretheory.html", "Chapter 3 Measure Theory 3.1 Sigma-algebra 3.2 Measure", " Chapter 3 Measure Theory 측도론이란, 간단히 말하면 집합의 크기를 측정하기 위한 학문입니다. 특히, 함수공간과 확률공간 같이 추상적인 공간을 다룰 때에 중요한 학문이죠. 우리는 흔히 고등학교 과정에서 확률과 통계를 접하고는 확률을 다룰 수 있다라고 착각합니다. 예를 들어, 확률이란 무엇인가? 라는 질문에 대해서 보통 다음과 같은 정의를 인용할 것입니다. Example 1 - High School Probability Probability of occurrence of events \\(A\\) in sample space \\(\\Omega\\) is \\[ \\mathbf{P}(A) = \\frac{n(A)}{n(\\Omega)}\\] 위의 정의를 이용하면 아주 간단명료하게 수학적 확률을 계산할 수 있습니다. 예를 들어, 주사위를 던졌을 때, 1이 나올 확률은 \\(\\left\\{1,2,3,4,5,6 \\right\\}\\)을 전체집합으로 설정하면 전체 6개 중에 1이 발생할 사건은 1개이기에 확률은 \\(\\frac{1}{6}\\)이 됩니다. 하지만, 다음의 경우에는 난처해집니다. Example 2 - Common High School Problem 정사각형 과녁 안에 원 모양 과녁이 네 변에 모두 내접하여 있을 때, 화살이 원 안에 명중할 확률을 구하여라. 간단한 확률 지식이 있는 사람이라면 이 문제를 \\(\\frac{\\text{원의 넓이}}{\\text{전체 정사각형의 넓이}}\\)로 접근하여 \\(\\frac{\\pi}{4}\\)임을 알아낼 수 있을 것입니다. 그런데 이는 앞에서의 정의와 대치됩니다. 분명 우리가 배운 정의에 의하면 사건이 발생할 경우의 수를 전체 경우의 수로 나누어 구해야 하는데, 전체 경우의 수는 얼마일까요? 하다 못해 원의 경우의 수는 어떻게 접근해야 할까요? 우리는 지금까지 아무런 의심 없이 구해왔습니다만, 이제부터 의심을 가질 필요가 있습니다. 확률은 특정 경우에서는 경우의 수 문제로 치환될 수 있지만, 집합이 무한해지는 순간 우리가 정의한 확률에 부합하지 않게 됩니다. 따라서 우리는 확률을 보다 엄밀하게 정의해야할 필요가 있습니다. 그리고 그것을 위해서는 먼저 집합의 크기를 정의해야 합니다. 바로 이를 위해서 측도론이 필요한 것입니다. 이제 측도론의 필요성은 잘 알았지만, 측도론은 상당히 추상적인 학문이라 곧바로 집합의 크기를 정의내릴 수는 없습니다. 집합의 크기가 무엇이다 말하기 전에 측정 가능한 집합에 대해서 먼저 논의해봅시다. 일단, 측정도 모르고 측정 가능성도 모르겠지만 일단 어떤 집합 \\(U, V\\)가 크기를 잴 수 있는 집합(가측집합; Measurable Set)이라 전제해봅시다. 그렇다면 직관적으로 다음의 사실들을 받아 들일 수 있습니다. \\(U\\cup V\\) is measurable \\(U \\cap V\\) is measurable \\(U^c,~ V^c\\) is measurable 하지만 수학자들은 이런 모호한 직관으로서의 정의를 좋아하지 않습니다. 이런 규칙들을 모아 좀 더 엄밀한 표현으로 바꾸어 하나의 우아한 규칙으로 정의내리고 받아들입니다. 수학에서 이러한 규칙을 대수(Algebra)라고 부릅니다. 3.1 Sigma-algebra Definition 1 - \\(\\sigma\\)-algebra Let \\(S\\) be a set, and let \\(\\mathcal{F}\\) be a family of subsets of \\(S\\). \\(\\mathcal{F}\\) is called a \\(\\sigma\\)-algebra if 1. \\(\\emptyset \\in \\mathcal{F}\\) 2. \\(A \\in \\mathcal{F}\\) implies \\(A^c \\in \\mathcal{F}\\) 3. \\(A_1, A_2,\\cdots \\in \\mathcal{F}\\) implies \\(\\bigcup_{i=1}^\\infty A_i \\in \\mathcal{F}\\) 정의는 무척 복잡해보이지만, 사실 의미 자체는 간단합니다. 대수는 일종의 규칙을 담아 놓은 집합입니다. 예를 들어, 위상수학에서의 Topology는 모든 열린 집합들의 집합이고, 여기서 말하는 \\(\\sigma\\)-algebra(시그마대수)는 모든 가측집합들의 집합입니다. 정의자체도 하나씩 살펴보면 충분히 납득이 가능합니다. 공집합은 당연하게도 크기가 0일 것이므로 측정가능한 집합이며, 어떤 집합 \\(A\\)가 측정가능하다면 (이를 수학에서는 \\(A\\in\\mathcal{F}\\)라 표현합니다.) 그의 여집합 또한 측정할 수 있을 것입니다. 마지막으로 측정 가능한 집합들의 합집합 또한 측정 가능할 것입니다. 이 외에도 전체집합이 측정가능하다는 사실을 1번과 2번 정의로부터 이끌어낼 수 있고, 2번과 3번 정의를 이용하면 합집합 뿐만 아니라 교집합 또한 측정 가능하다는 사실을 유추해낼 수 있습니다. 이제 대수를 정의하였으니 우리가 다룰 공간을 명시해봅시다. Definition 2 - Measurable Space Let \\(S\\) be a set, and let \\(\\mathcal{F}\\) be a \\(\\sigma\\)-algebra of subsets of \\(S\\). Then \\((S, \\mathcal{F})\\) is called a measurable space. The elements of \\(\\mathcal{F}\\) are called measurable sets. 이제 기본 틀은 정리했으니 적응하기 위하여 조금 더 생각을 해봅시다. 어떤 집합 \\(S\\)에 대하여 가장 작은 \\(\\sigma\\)-algebra와 가장 큰 \\(\\sigma\\)-algebra는 뭘까요? 일단, 정의에 의해 공집합은 무조건 측정가능하고 두 번째 정의에 의해 전체집합도 측정가능하므로 가장 작은 시그마대수는 \\(\\mathcal{F} = \\left\\{\\emptyset, S \\right\\}\\)가 됩니다. 또한 시그마 대수는 어떤 집합의 부분집합의 모임이기 때문에 모든 부분집합의 집합(멱집합; Power set)이 가장 큰 시그마 대수가 될 것입니다. 이는 \\(\\mathcal{F} = \\mathcal{P}(S)\\)로 표기합니다. 고등학교 시절에 부분집합을 배울 때, 어떤 집합을 포함하는 부분집합의 개수는? 이라는 문제를 본 적이 있을 겁니다. 되게 의미 없는 일 같지만 수학에서는 어떤 집합을 포함하고 있는 지의 여부가 상당히 중요합니다. 시그마 대수에서도 마찬가지인데 어떤 집합을 반드시 포함하고 있는 시그마 대수를 “그 집합에 의하여 발생한 시그마 대수이다” 라고 정의할 것입니다. 수학적 정의는 다음과 같습니다. Definition 3 - Generated \\(\\sigma\\)-algebra Let \\(S\\) be a set and \\(G\\) be a family of subsets of \\(S\\). The smallest \\(\\sigma\\)-algbera which contains \\(G\\) is called generated \\(\\sigma\\)-algebra with respect to \\(G\\) denoted by \\(\\sigma(G)\\). 이제 이 정의를 아주 유명한 규칙 공간에 적용해보겠습니다. 바로 위상공간(Topological Space)에 말이죠. Definition 4 - Borel \\(\\sigma\\)-algebra The Borel \\(\\sigma\\)-algebra \\(\\mathcal{B}\\) of a topological space \\((S, \\mathcal{T})\\) is the \\(\\sigma\\)-algebra generated by \\(\\mathcal{T}\\). 위 정의를 이해하기 위하여 굳이 위상수학까지 공부하지 않아도 됩니다. (물론, 하면 좋지만요.) 우리는 앞으로 관측 공간인 \\(\\mathbb{R}^d\\)에서의 대수만 사용할 것이기 때문이죠. 간단히 말하자면 \\(n\\)차원 실수공간의 위상은 \\(n\\)차원 직육면체로 표현됩니다. 1차원에서는 직선, 2차원에서는 직사각형 이런 식이죠. 따라서 위의 정의에 따르면 이런 직사각형들이 모두 측정가능하다면, 그 공간을 일컬어 Borel \\(\\sigma\\)-algebra 가 존재하는 공간이라 합니다. 지금까지는 공간, 집합에 대해서만 다뤘는데, 정작 가장 중요하게 다룰 것은 그 공간과 집합에 작용하는 함수입니다. 위상수학이나 해석학을 배웠다면 다음의 정의는 아주 쉽게 다가올 것입니다만, 하지 않았더라도 받아들이면 큰 문제는 없습니다. Definition 5 - Measurable function Let \\((S, \\mathcal{F})\\), \\((S&#39;, \\mathcal{F}&#39;)\\) be measurable spaces and \\(f:\\, S \\rightarrow S&#39;\\). If \\(\\forall X \\in \\mathcal{F}&#39;\\), \\(f^{-1}(X) \\in \\mathcal{F}\\) then \\(f\\) is called measurable function. 이 정의를 어떻게 사용하는지 간단한 예시로 설명해보겠습니다. Definition 6 - Indicator function The indicator function of a subset \\(A\\) of a set \\(X\\) is a function \\[I_A(x): \\, X \\rightarrow \\left\\{0, 1 \\right\\}\\] defined as \\[I_A(x) \\equiv \\begin{cases} 1 &amp; \\text{if } x \\in A, \\\\ 0 &amp; \\text{if } x \\notin A. \\end{cases}\\] Example 3 - Indicator function is measurable Let \\(A\\in\\mathcal{F}\\) then \\(I_A\\) is measurable function. 위 예시의 증명은 아주 간단하므로 생략하겠습니다. 한 번 해보고 넘어가면 이해가 잘 될테니 꼭 해보시길 바랍니다. 이제 측정가능성은 대부분 논의했으니 진정한 목표인 측도로 가봅시다. 3.2 Measure Definition 7 - Measure Let \\((S,\\mathcal{F})\\) be measurable space and let \\(\\mu:\\, \\mathcal{F} \\rightarrow [0,\\infty)\\) be a function. \\(\\mu\\) is measure on \\(\\mathcal{F}\\) if 1. \\(\\mu(\\emptyset) = 0\\) 2. \\(\\mu\\) is \\(\\sigma\\)-additive. That is, for disjoint family \\(\\left\\{A_i \\right\\}_{i=1}^\\infty \\in \\mathcal{F}\\), \\[\\mu \\left(\\bigcup_{i=1}^\\infty A_i\\right) = \\sum_{i=1}^\\infty \\mu(A_i)\\] 정의는 아주 자명합니다. 비록 크기가 무엇인지 감이 잘 오진 않더라도 공집합의 크기는 반드시 0일 것이며 전혀 겹치지 않는 집합들의 합집합의 크기는 각 집합들의 크기의 합과 같을 것입니다. 또한 위 정의에서 유심히 보아야 할 부분은 \\(\\mu\\) 즉, 측도가 측정가능한 집합을 음이 아닌 값의 실수로 보내는 함수라는 것입니다. 우리는 음의 부피를 정의하지 않고 또한 음의 확률을 정의하지 않습니다. 사실 너무나 당연하게 써 왔던 이러한 사실을 측도라는 비교적 간단한 정의를 이용하여 수학적으로 못 박아둔 것이죠. 이제 측도도 생겼으니 새로운 공간을 정의하여 봅시다. Definition 8 - Measure space The triple \\((S, \\mathcal{F}, \\mu)\\) is a measure space if \\((S,\\mathcal{F})\\) is a measurable space and \\(\\mu\\) is a measure on \\(\\mathcal{F}\\). 순수 수학자들이 아닌 이상 응용수학이나 물리, 통계학에서는 측정 가능성도 꽤 중요하겠지만 더욱 중요한 것은 정확히 측정하는 것입니다. 따라서 이제부터는 새로 정의한 측도공간(Measure Space) 을 사용할 것입니다. 이러한 측도 공간에서도 \\(n\\)차원 실수 공간은 특히 더욱 중요해서 따로 이름을 붙입니다. Definition 9 - Lebesgue measure The Lebesgue measure \\(\\lambda\\) on \\(\\mathbb{R}^d\\) is a measure on the Borel \\(\\sigma\\)-algebra of \\(\\mathbb{R}^d\\) such that the \\(\\lambda\\) measure of each rectangle equals to its volume. 정의는 조금 복잡할지라도 의미는 간단합니다. 직육면체의 부피를 측정하는 측도를 르벡 측도(Lebesgue measure)라고 부른다는 것이죠. Lebesgue의 이름은 수학 어디서나 등장하기 때문에 익숙해지는 것이 좋습니다. 이제 측도도 생겼으니 본격적으로 집합의 크기를 측정해봅시다. 물론, 처음부터 복잡한 함 수로 표현되는 공간의 크기를 구하기란 아주 어려운 일이므로, 우리는 아주 단순한 함수부터 시작해서 일반화하는 방향으로 접근할 것입니다. Definition 10 - Simple function A function, which image is finite, is called simple function. Property 1 - Simple function with indicator function If \\(\\varphi: \\chi \\rightarrow \\mathbb{R}\\) is simple function then we can write \\[\\varphi = \\sum_{i=1}^n a_i I_{E_i}\\] where \\(\\left\\{a_i \\right\\}\\) is image of \\(\\varphi\\) and \\(E_i = \\varphi^{-1}(\\left\\{a_i \\right\\})\\). 수학에서 사용되는 전형적인 단순한 함수는 바로 위에서 정의한 Simple function입니다. 사실 본래 정의는 매우 간단하지만, 보통 Simple function이라 하면 대개 Property 1을 생각합니다. 대체 이 함수가 뭐가 단순한건지 의아하겠지만, 이러한 함수에 대해서는 적분을 아주 쉽게 정의할 수 있습니다. Definition 11 - Lebesgue integral for simple function Let \\((S,\\mathcal{F}, \\mu)\\) be measure space and \\(\\displaystyle f = \\sum_{i=1}^n a_i I_{E_i}\\) be a simple function. Then the Lebesgue Integral of \\(f\\) with respect to \\(\\mu\\) is defined by \\[ \\int_S f d\\mu = \\sum_{i=1}^n a_i \\mu(E_i) \\] 분명 정의는 했는데 대체 무슨 뜻인지 의아할 수 있으므로 쉽게 예시를 들어봅시다. Example 4 - Example of Lebesgue integral for simple function \\(f\\) is a simple function given as: \\[f = \\begin{cases} 1 &amp; \\text{if } 0 \\leq x &lt; 1 \\\\ 2 &amp; \\text{if } 1 \\leq x &lt; 3 \\\\ 3 &amp; \\text{if } 3 \\leq x &lt; 4 \\\\ 0 &amp; \\text{otherwise} \\end{cases}\\] then find integral of \\(f \\in \\mathbb{R}\\). 이 문제는 직사각형의 넓이만 구할 수 있으면 아주 쉽게 구할 수 있습니다. 일단 위 함수를 그리면 다음과 같습니다. Figure 3.1: Simple function example 이 함수를 Indicator function을 이용하여 식으로 구해보면 다음과 같습니다. \\[f(x) = 1 \\times I_{E_1} + 2 \\times I_{E_2} + 3 \\times I_{E_3}\\] 이때, \\(E_1, E_2, E_3\\)는 각각 \\([0, 1),\\, [1, 3),\\, [3, 4)\\)입니다. 이제 앞에서 정의했던대로 이 함수의 르벡 적분(Lebesgue Integral)을 구해보면 쉽게 답을 얻을 수 있습니다. \\[ \\int_{\\mathbb{R}} f d\\mu = \\sum_{i=1}^3 a_i \\mu(E_i) = 1\\times 1 + 2\\times 2 + 3\\times 1 = 8\\] 식을 자세히 보면 그저 직사각형의 넓이들을 더한 값과 같다는 것을 알 수 있습니다. 이렇게보면 굳이 쉬운 문제를 어렵게 푸는 것 같아 보이지만, 르벡 적분의 의의는 이런 단순한 함수 뿐만 아니라, 무한한 집합이나 추상적인 집합에 대해서도 적분 값을 구할 수 있다는 것입니다. 항상 이런 단순한 정의로 문제를 풀 수 있으면 좋겠지만 대다수의 경우에 함수들은 Simple function 으로 나타낼 수 없습니다. (간단히 연속함수의 예시만 봐도 알 수 있죠.) 따라서 우리는 기존 정의를 확장해야할 필요가 있습니다. Definition 12 - Lebesgue integral for positive definite function Let \\((S, \\mathcal{F}, \\mu)\\) be a measure space and \\(f: S \\rightarrow [0, \\infty)\\) is measurable, then the Lebesgue integral of \\(f\\) with respect to \\(\\mu\\) is defined by \\[\\int_S f d\\mu = \\sup \\left\\{\\int_S \\varphi d\\mu:~ \\varphi \\text{ is simple and measurable}, ~ 0\\leq \\varphi \\leq f \\right\\}\\] 위 정의를 보면 앞에서 왜 Simple function을 도입해야 했는지 납득이 될 것입니다. 마치 리만 적분(Riemann integral)에서 작은 직사각형들로 잘게 쪼개어 적분을 표현하듯이 르벡 적분에서는 함수를 최대한의 Simple function으로 쪼개어 적분합니다. 물론 위 정의에서는 양의 함수만 정의하기에 음의 함수까지도 정의를 확장해야 합니다. Definition 13 - Lebesgue integral for arbitrary measurable function Let \\((S, \\mathcal{F}, \\mu)\\) be a measure space and \\(f:\\, S\\rightarrow \\mathbb{R}\\) is arbitrary measurable function. Then \\[ \\int_S f d\\mu = \\int_S f^{+}d\\mu - \\int_S f^{-}d\\mu\\] where \\(f^{+} = \\max \\left\\{f(x), 0 \\right\\},~ f^- = \\max \\left\\{-f(x), 0 \\right\\}\\). 다음은 르벡 적분의 주요 정리들입니다. Theorem 1 - Beppo-Levy theorem If \\(f_n \\rightarrow f~(\\text{mod } \\mu)\\) in a monotone increasing way then \\[\\int \\lim_{n\\rightarrow \\infty} f_n d\\mu = \\lim_{n \\rightarrow \\infty} \\int f_n d\\mu\\] Theorem 2 - Fatou’s lemma Let \\((S, \\mathcal{F}, \\mu)\\) be a measure space and \\(\\forall n \\in \\mathbb{N},~f_n: S\\rightarrow [0,\\infty)\\) be measurable function. Then \\[ \\int_S \\underset{n\\rightarrow\\infty}{\\text{liminf}} f_n d\\mu \\leq \\underset{n\\rightarrow \\infty}{\\text{liminf}} \\int_S f_n d\\mu \\] Theorem 3 - Lebesgue dominated convergence theorem Let \\((S, \\mathcal{F}, \\mu)\\) be a measure space. Assume that \\(f_n\\rightarrow f~(\\text{mod }\\mu)\\) and \\(|f_n(s)| \\leq g(s),~\\forall s \\in S, ~n\\in\\mathbb{N}\\) where \\(\\displaystyle \\int_S g d\\mu &lt; \\infty\\). Then \\[\\int_S f d\\mu = \\lim_{n\\rightarrow \\infty} \\int_S f_n d\\mu\\] 위 정리들은 수학에서는 상당히 중요한 정리지만, 지금 당장 우리에게는 많이 필요한 것은 아니니 한 번 보고 넘어가면 충분합니다. 하지만 다음 정의들과 정리들은 꽤 중요하니 눈여겨 봐두시길 바랍니다. Definition 14 - Induced measure Let \\((S, \\mathcal{F}, \\mu)\\) be a measure space and \\(f\\) be a measurable function. Then \\(f\\) induces a measure \\(\\nu\\) on the Borel \\(\\sigma\\)-algebra \\(\\mathcal{B}\\) \\[\\nu(B) = \\mu(f^{-1}(B)),~\\forall B \\in \\mathcal{B}\\] Theorem 4 - Change measure Let \\(\\nu\\) be measure on the Borel \\(\\sigma\\)-algebra of \\(\\mathbb{R}\\) and let \\(f, g\\) be measurable functions. Then \\(\\forall B \\in \\mathcal{B}\\), \\[\\int_B g d\\mu = \\int_{f^{-1}(B)} g \\circ f d\\nu\\] Definition 15 - Product measure Let \\(\\nu_1,\\nu_2\\) be measures on \\((S_1,\\mathcal{F}_1),~(S_2,\\mathcal{F}_2)\\). Let \\((S, \\mathcal{F})\\) be measurable space such that \\(S = S_1 \\times S_2\\) and \\(\\mathcal{F} = F_1 \\times F_2\\) whenever \\(F_1 \\in \\mathcal{F}_1,~F_2 \\in \\mathcal{F}_2\\). \\(\\nu\\) is called the product measure of \\(\\nu_1, \\nu_2\\) on \\(\\mathcal{F}\\) if \\[\\nu(F_1 \\times F_2) = \\nu(F_1) \\times \\nu(F_2)\\] Theorem 5 - Fubini’s theorem Let \\(h\\) be a measurable function on the product space \\((S,\\mathcal{F})\\) then \\[\\int_S h(u,v)d\\mu = \\int_{S_1}\\left(\\int_{S_2}h(u,v)d\\nu_2\\right)d\\nu_1 = \\int_{S_2}\\left(\\int_{S_1}h(u,v)d\\nu_1\\right)d\\nu_2\\] 위 정의와 정리들은 우리가 흔히 리만 적분에서 적분 변수를 변경할 때 사용했던 것과 비슷하므로 외우기는 쉬울 겁니다. 여기서는 굳이 증명이 필요치 않으니 생략하고 넘어가겠습니다. 그럼 이제 본격적으로 확률론의 세계로 들어가겠습니다. "],
["prob.html", "Chapter 4 Probability 4.1 Inequalities", " Chapter 4 Probability Definition 16 - Probability space A measure space \\((\\Omega, \\mathcal{F}, \\mathbf{P})\\) is called a probability space if \\(\\mathbf{P}(\\Omega) = 1\\). \\(\\Omega\\) is called the sample space, the measure sets are called events, and the measurable functions are called random variables. If \\(X_1, X_2, \\cdots, X_n\\) are random variables then \\(X = (X_1,X_2,\\cdots,X_n)\\) is a vector-valued random variable. 확률공간의 정의는 간단합니다. 어떤 측도공간 \\((\\Omega, \\mathcal{F}, \\mathbf{P})\\)가 \\(\\mathbf{P}(\\Omega) = 1\\)을 만족할 때, 그 측도공간을 확률 공간이라 부른다는 것입니다. 또한, 전체 집합인 \\(\\Omega\\)는 표본공간(Sample space)이라 부르며 가측집합(Measurable set)들은 사건(Events)이라 부르고 가측함수(Measurable function)들은 확률변수(Random variable)라고 부른다는 것이죠. 계속해서 다른 정의들을 봅시다. Definition 17 - Distribution of Random variables Let \\(X\\) be a random variable, then \\(X\\) induces the measure \\(\\mu\\) on the Borel \\(\\sigma\\)-algebra of \\(\\mathbb{R}\\) by \\[\\mu(B) = \\mathbf{P}\\left\\{\\{ \\omega:\\, X(\\omega) \\in B\\} \\right\\} \\equiv \\mathbf{P}\\left\\{X \\in B \\right\\},~ B \\in \\mathcal{B}\\] The induced probability measure \\(\\mu\\) is called the distribution of random variable \\(X\\). 앞에서 말한 Induced measure가 뜬금없이 튀어나왔는데, 굳이 그 부분을 볼 필요까지는 없습니다. 여기서 기억해야 할 것은 \\(\\mu(B) = \\mathbf{P}\\left\\{X \\in B \\right\\}\\)입니다. 이는 우리가 흔히 사용하던 확률과 상당히 유사합니다. 집합 \\(B\\)에 확률변수 \\(X\\)가 들어갈 확률을 새로운 \\(\\mu\\)라는 측도로 정의한 것이죠. 이때, \\(\\mu\\)의 이름은 확률변수 \\(X\\)의 분포(Distribution)입니다. 즉, 흔히 말하는 확률분포를 구한다는 것은 측도 \\(\\mu\\)를 구한다는 것과 동치입니다. 이제 볼 정의는 상당히 많이 사용하므로 특히나 주의 깊게 보시길 바랍니다. Definition 18 - Expectation Let \\(X\\) be a random variable. The expectation of \\(X\\) is the integral of \\(X\\) with respect to distribution \\(\\mu\\) of \\(X\\). \\[\\mathbf{E}\\left\\{X \\right\\} = \\int_{\\mathbb{R}} x \\mu(dx)\\] 위에 명시한 적분이 낯설 수 있는데, 이는 보통 르벡 적분을 표현하는 방식이 여러가지이기 때문입니다. \\[\\int_S f d\\mu = \\int_S f(s) \\mu(ds)\\] 하지만 이를 차치하고서라도 위 정의는 이상해보일 수 있습니다. \\(X\\)에 대한 기댓값이라면서 \\(X\\)가 적분식에 포함되어 있지 않습니다. 하지만 자세히 보면 \\(\\mu\\)가 \\(X\\)의 분포이기에 \\(\\mu\\)안에 \\(X\\)의 값이 포함되어 있다는 것을 알 수 있습니다. 이제 기댓값의 정의가 나왔으니 자연스러운 수순으로 분산의 정의를 봅시다. Definition 19 - Variance Let \\(X\\) be a random variable. The variance of \\(X\\) is \\[\\text{Var}\\left\\{X \\right\\} = \\mathbf{E}\\left\\{(X - \\mathbf{E}\\{X\\})^2 \\right\\}\\] 우리가 알고 있던 분산의 정의와 정확히 일치합니다. 즉, 측도론으로부터 유도되긴 했지만 실제 계산은 고등학교에서 배웠던 확률과 통계와 크게 다르지 않다는 것을 알 수 있습니다. 이제 또 다른 익숙한 개념을 새롭게 정의해봅시다. Definition 20 - Joint distribution &amp; Independence Let \\(X_1, \\cdots, X_n\\) be random variables. They induce the measure \\(\\mu^{(n)}\\) on the Borel \\(\\sigma\\)-algebra of \\(\\mathbb{R}^n\\) with the property \\[\\mu^{(n)}(B_1 \\times \\cdots \\times B_n) = \\mathbf{P}\\left\\{X_1\\in B_1,\\cdots,X_n\\in B_n \\right\\},~ B_1,\\cdots,B_n \\in \\mathcal{B}\\] \\(\\mu^{(n)}\\) is called the joint distribution of random variables. Let \\(\\mu_i\\) be the distribution of \\(X_i\\), the random variables \\(\\left\\{X_i \\right\\}_{i=1}^n\\) are independent if \\(\\mu^{(n)}\\) is the product measure of \\(\\left\\{\\mu_i \\right\\}_{i=1}^n\\). The events \\(A_1,\\cdots,A_n \\in \\mathcal{F}\\) are independent if the random variables \\(I_{A_1},\\cdots,I_{A_n}\\) are independent. 위 정의는 한 마디로 요약하면 확률변수 \\(n\\)개의 분포가 각각의 확률변수들의 분포에 대해 곱측도(Product measure)이면 확률변수들을 독립이라 부르겠다는 것입니다. 우리가 알던 정의와 조금 달라보이지만, 확률측도로 변경하여 보면 위 정의는 다음 식으로 귀결됩니다. \\[\\mathbf{P}\\left\\{X_1\\in B_1, \\cdots, X_n \\in B_n \\right\\} = \\mathbf{P}\\left\\{X_1 \\in B_1 \\right\\} \\times \\cdots \\times \\mathbf{P}\\left\\{X_n \\in B_n \\right\\}\\] 이제 우리가 알던 독립의 정의와 같아졌습니다. 또한 위 정의는 단순히 확률 변수들의 독립 뿐만 아니라 사건들의 독립도 정의하였습니다. 특이하게도 각 사건들의 Indicator function들이 독립이면 그 사건들도 독립이라고 정의되어 있는데 Indicator function 역시 Measurable function이므로 확률 변수에 해당하니 정의 자체는 충분히 받아들일 수 있습니다. 위 정의를 받아들이면 아래의 중요한 정리를 쉽게 유도할 수 있습니다. Theorem 6 - Independence with Expectation If \\(X_1, \\cdots, X_n\\) are independent and have finite expectations then \\[\\mathbf{E}\\left\\{X_1 X_2 \\cdots X_n \\right\\} = \\mathbf{E}\\{X_1\\}\\cdots \\mathbf{E}\\{X_n\\}\\] 증명은 Independence, product measure의 정의들과 Fubini’s theorem을 적용하면 쉽게 증명되니 생략하겠습니다. 4.1 Inequalities 이제 지루한 수학 단원의 마지막입니다. 앞으로 논리를 전개하는데 유용한 부등식들을 소개하고 마치도록 하겠습니다. Cauchy-Schwarz: \\(|\\mathbf{E}\\{XY\\}| \\leq \\sqrt{\\mathbf{E}\\{X^2\\}\\mathbf{E}\\{Y^2\\}}\\) Hölder: \\(p,q\\in(1,\\infty),\\,\\frac{1}{p} + \\frac{1}{q} = 1\\, \\Rightarrow \\mathbf{E}\\{|XY|\\} \\leq \\left(\\mathbf{E}\\{|X^p|\\}\\right)^{1/p} \\cdot \\left(\\mathbf{E}\\{|Y|^q\\}\\right)^{1/q}\\) Markov: Given non-negative \\(X\\), \\(\\forall t &gt; 0, ~ \\mathbf{P}(X \\geq t) \\leq \\frac{\\mathbf{E}(X)}{t}\\) Chebyshev: \\(\\forall t &gt;0, ~ \\mathbf{P}(|X - \\mathbf{E}X| \\geq t) \\leq \\frac{\\text{Var}(X)}{t^2}\\) Chebyshev - Cantelli: \\(\\forall t \\geq 0,~\\mathbf{P}(X - \\mathbf{E}X &gt; t) \\leq \\frac{\\text{Var}(X)}{\\text{Var}(X) + t^2}\\) 위의 부등식들도 상당히 중요하지만 다음 2개의 부등식은 특히나 중요하기에 정리로 따로 정리하였습니다. Theorem 7 - Jensen’s inequality If \\(F\\) is a real-valued convex function on a finite or infinite interval of \\(\\mathbb{R}\\) and \\(X\\) is a random variable with finite expectation taking its values in this interval. then \\[f(\\mathbf{E}(X)) \\leq \\mathbf{E}(f(X))\\] Theorem 8 - Association inequality Let \\(X\\) be a real-valued random variable and \\(f,g\\) are real-valued function 1. \\(f,g\\) are monotone non-decreasing then \\[ \\mathbf{E}\\left\\{f(X)g(X) \\right\\} \\geq \\mathbf{E}\\left\\{f(X) \\right\\} \\mathbf{E}\\left\\{g(X) \\right\\}\\] 2. \\(f\\) is monotone increasing and \\(g\\) is monotone decreasing then \\[\\mathbf{E}\\left\\{f(X)g(X) \\right\\}\\leq \\mathbf{E}\\left\\{f(X) \\right\\}\\mathbf{E}\\left\\{g(X) \\right\\}\\] 이것으로 기초 측도론과 확률론은 모두 끝났습니다. 이제 추상의 영역에서 조금 벗어나서 실제로 많이 사용되는 확률분포들에 대해서 알아보도록 하겠습니다. "],
["dist.html", "Chapter 5 Probability Distributions 5.1 Binary Variables", " Chapter 5 Probability Distributions 이 단원에서는 실제로 많이 쓰이는 확률 분포 몇 개와 그 성질들을 간략히 요약하고자 합니다. 결과는 모두 (Bishop 2006)의 Appendix B에 있으니 참고하시길 바랍니다. 과정은 대개 다음과 같이 이루어질 것입니다. 확률 분포 정의 대푯값(Representative value) 계산 최대가능도추정(Maximally Likelihood Estimation) Bayesian Update Random number generator (Programming) 편의상 증명은 대부분 영어로 진행하겠습니다. 5.1 Binary Variables 5.1.1 Bernoulli Distribution Definition 5.1.1 - Bernoulli distribution Let consider a single binary random variable \\(x\\in\\{0,1\\}\\). Suppose the probability of \\(x=1\\) is given as \\(p(x=1|\\mu) = \\mu\\) where \\(0\\leq \\mu \\leq 1\\) then \\[\\text{Bern}(x|\\mu) = \\mu^x(1 - \\mu)^{1-x}\\] is called Bernoulli distribution. Property 5.1.2 - Representative values of Bernouli distribution Let \\(\\text{Bern}(x|\\mu)\\) be given Bernoulli distribution. Then \\[\\begin{align} \\mathbb{E}[x] &amp;= \\mu \\\\ \\text{var}[x] &amp;= \\mu(1-\\mu) \\end{align}\\] Theorem 5.1.3 - MLE for Bernoulli distribution Let \\(\\mathcal{D} = \\{x_1, \\cdots, x_N\\}\\) be i.i.d data belong to \\(\\text{Bern}(x|\\mu)\\). Applying maximally likelihood estimation, then \\[\\mu_{ML} = \\frac{1}{N}\\sum_{i=1}^N x_n \\] Proof for Thm 5.1.3 Since there is i.i.d assumption, the likelihood given as \\[p(\\mathcal{D}|\\mu) = \\prod_{n=1}^N p(x_n | \\mu) = \\prod_{n=1}^N \\mu^{x_n} (1 - \\mu)^{1-x_n}\\] For convenience, let’s obtain log likelihood. \\[\\begin{align} \\ln p(\\mathcal{D}| \\mu) = \\sum_{n=1}^N \\ln p(x_n | \\mu) &amp;= \\sum_{n=1}^N \\left\\{x_n \\ln \\mu + (1-x_n)\\ln(1-\\mu) \\right\\}\\\\ &amp;= \\ln \\mu \\sum_{n=1}^N x_n + \\ln(1-\\mu) \\sum_{n=1}^N (1-x_n) \\\\ &amp;= (\\ln\\mu - \\ln(1-\\mu))\\sum_{n=1}^N x_n + N \\ln(1-\\mu) \\end{align}\\] Then for MLE, let’s differentiate log likelihood with \\(\\mu\\). \\[\\frac{\\partial}{\\partial \\mu}\\ln p(\\mathcal{D}|\\mu) = \\frac{1}{\\mu}\\sum_{n=1}^N x_n - \\frac{1}{1-\\mu}\\sum_{n=1}^N (1 - x_n) = 0\\] Therefore we can find \\(\\mu_{ML}\\). \\[\\therefore\\,\\mu_{ML} = \\frac{1}{N}\\sum_{n=1}^N x_n\\] 이번에는 균등 분포(Uniform distribution)로 부터 베르누이 분포를 구현해보도록 하겠습니다. Algorithm 5.1.4 - Uniform to Bernoulli We want to generate \\(X \\sim \\text{Bern}(x | \\mu)\\). 1. Generate \\(U \\sim \\text{Unif}(0,1)\\) 2. If \\(U \\leq \\mu\\) where \\(\\mu \\in [0, 1]\\) then \\(X = 1\\) else \\(X = 0\\). 이 간단한 알고리즘을 Rust를 이용해서 나타내면 다음과 같습니다. // Generate 100 samples of Bern(x|0.1) extern crate rand; use rand::prelude::*; fn main() { let sample_size = 100; let mut rng = thread_rng(); let mut v = vec![0usize; 100]; let mu: f64 = 0.1; for i in 0 .. sample_size { let u = rng.gen_range(0f64, 1f64); if u &lt;= mu { v[i] = 1; } else { v[i] = 0; } } println!(&quot;Samples:\\n{:?}&quot;, v); } 이미 구현되어 있는 라이브러리인 Peroxide을 사용한 결과는 다음과 같습니다. extern crate peroxide; use peroxide::*; fn main() { let b = Bernoulli(0.1); let b_samples = b.sample(100); b.print(); } References "],
["references.html", "References", " References "]
]
